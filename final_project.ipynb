{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# %pip install ensemble_boxes\n",
    "# %pip install albumentations\n",
    "# %pip install effdet\n",
    "# %pip install natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\V'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\V'\n",
      "C:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Temp\\ipykernel_27360\\4183875739.py:3: SyntaxWarning: invalid escape sequence '\\V'\n",
      "  testing_label_relative = 'Thesis_Folder\\VALDO_Dataset\\Task2'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cohort1': ['sub-101',\n",
       "  'sub-102',\n",
       "  'sub-103',\n",
       "  'sub-104',\n",
       "  'sub-105',\n",
       "  'sub-106',\n",
       "  'sub-107',\n",
       "  'sub-108',\n",
       "  'sub-109',\n",
       "  'sub-110',\n",
       "  'sub-111'],\n",
       " 'cohort2': ['sub-201',\n",
       "  'sub-202',\n",
       "  'sub-203',\n",
       "  'sub-204',\n",
       "  'sub-205',\n",
       "  'sub-206',\n",
       "  'sub-207',\n",
       "  'sub-208',\n",
       "  'sub-209',\n",
       "  'sub-210',\n",
       "  'sub-211',\n",
       "  'sub-212',\n",
       "  'sub-213',\n",
       "  'sub-214',\n",
       "  'sub-215',\n",
       "  'sub-216',\n",
       "  'sub-217',\n",
       "  'sub-218',\n",
       "  'sub-219',\n",
       "  'sub-220',\n",
       "  'sub-221',\n",
       "  'sub-222',\n",
       "  'sub-223',\n",
       "  'sub-224',\n",
       "  'sub-225',\n",
       "  'sub-226',\n",
       "  'sub-227',\n",
       "  'sub-228',\n",
       "  'sub-229',\n",
       "  'sub-230',\n",
       "  'sub-231',\n",
       "  'sub-232',\n",
       "  'sub-233',\n",
       "  'sub-234'],\n",
       " 'cohort3': ['sub-301',\n",
       "  'sub-302',\n",
       "  'sub-303',\n",
       "  'sub-304',\n",
       "  'sub-305',\n",
       "  'sub-306',\n",
       "  'sub-307',\n",
       "  'sub-308',\n",
       "  'sub-309',\n",
       "  'sub-310',\n",
       "  'sub-311',\n",
       "  'sub-312',\n",
       "  'sub-313',\n",
       "  'sub-314',\n",
       "  'sub-315',\n",
       "  'sub-316',\n",
       "  'sub-317',\n",
       "  'sub-318',\n",
       "  'sub-319',\n",
       "  'sub-320',\n",
       "  'sub-321',\n",
       "  'sub-322',\n",
       "  'sub-323',\n",
       "  'sub-324',\n",
       "  'sub-325',\n",
       "  'sub-326',\n",
       "  'sub-327']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "testing_label_relative = 'Thesis_Folder\\VALDO_Dataset\\Task2'\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "two_directories_up = os.path.abspath(os.path.join(current_directory, \"../../\"))\n",
    "\n",
    "# Combine the current directory with the relative path\n",
    "testing_label_absolute = os.path.join(two_directories_up, testing_label_relative)\n",
    "\n",
    "folders = [item for item in os.listdir(testing_label_absolute) if os.path.isdir(os.path.join(testing_label_absolute, item))]\n",
    "\n",
    "cases = {\"cohort1\": [], \"cohort2\": [], \"cohort3\": []}\n",
    "# Print the list of folders\n",
    "for folder in folders:\n",
    "    if \"sub-1\" in folder:\n",
    "        cases[\"cohort1\"].append(folder)\n",
    "    elif \"sub-2\" in folder:\n",
    "        cases[\"cohort2\"].append(folder)\n",
    "    else:\n",
    "        cases[\"cohort3\"].append(folder)\n",
    "\n",
    "cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-101\\\\sub-101_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-102\\\\sub-102_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-103\\\\sub-103_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-104\\\\sub-104_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-105\\\\sub-105_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-106\\\\sub-106_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-107\\\\sub-107_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-108\\\\sub-108_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-109\\\\sub-109_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-110\\\\sub-110_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-111\\\\sub-111_space-T2S_desc-masked_T2S.nii.gz']\n",
      "['c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-201\\\\sub-201_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-202\\\\sub-202_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-203\\\\sub-203_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-204\\\\sub-204_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-205\\\\sub-205_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-206\\\\sub-206_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-207\\\\sub-207_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-208\\\\sub-208_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-209\\\\sub-209_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-210\\\\sub-210_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-211\\\\sub-211_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-212\\\\sub-212_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-213\\\\sub-213_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-214\\\\sub-214_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-215\\\\sub-215_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-216\\\\sub-216_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-217\\\\sub-217_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-218\\\\sub-218_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-219\\\\sub-219_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-220\\\\sub-220_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-221\\\\sub-221_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-222\\\\sub-222_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-223\\\\sub-223_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-224\\\\sub-224_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-225\\\\sub-225_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-226\\\\sub-226_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-227\\\\sub-227_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-228\\\\sub-228_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-229\\\\sub-229_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-230\\\\sub-230_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-231\\\\sub-231_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-232\\\\sub-232_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-233\\\\sub-233_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-234\\\\sub-234_space-T2S_desc-masked_T2S.nii.gz']\n",
      "['c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-301\\\\sub-301_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-302\\\\sub-302_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-303\\\\sub-303_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-304\\\\sub-304_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-305\\\\sub-305_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-306\\\\sub-306_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-307\\\\sub-307_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-308\\\\sub-308_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-309\\\\sub-309_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-310\\\\sub-310_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-311\\\\sub-311_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-312\\\\sub-312_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-313\\\\sub-313_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-314\\\\sub-314_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-315\\\\sub-315_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-316\\\\sub-316_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-317\\\\sub-317_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-318\\\\sub-318_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-319\\\\sub-319_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-320\\\\sub-320_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-321\\\\sub-321_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-322\\\\sub-322_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-323\\\\sub-323_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-324\\\\sub-324_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-325\\\\sub-325_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-326\\\\sub-326_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\Thesis_Folder\\\\VALDO_Dataset\\\\Task2\\\\sub-327\\\\sub-327_space-T2S_desc-masked_T2S.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "cohort1_labels = []\n",
    "for case in cases[\"cohort1\"]:\n",
    "    img = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_desc-masked_T2S.nii.gz\"\n",
    "    cohort1_labels.append(img)\n",
    "print(cohort1_labels)\n",
    "\n",
    "cohort2_labels = []\n",
    "for case in cases[\"cohort2\"]:\n",
    "    img = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_desc-masked_T2S.nii.gz\"\n",
    "    cohort2_labels.append(img)\n",
    "print(cohort2_labels)\n",
    "\n",
    "cohort3_labels = []\n",
    "for case in cases[\"cohort3\"]:\n",
    "    img = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_desc-masked_T2S.nii.gz\"\n",
    "    cohort3_labels.append(img)\n",
    "print(cohort3_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from ensemble_boxes import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import natsort as ns\n",
    "import re\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\n",
    "from effdet.efficientdet import HeadNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0+cu118\n",
      "CUDA available: True\n",
      "Number of CUDA devices: 1\n",
      "CUDA device name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 #any constant\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change into the device name of your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_num = 'NVIDIA GeForce GTX 1650'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pretrained EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d3')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    \n",
    "    config.num_classes = 1\n",
    "    config.image_size=512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device_num)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = DetBenchEval(net, config)\n",
    "    net.eval()\n",
    "    device = torch.device(device_num)\n",
    "    return net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Axial marking from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axial_marking(label_path):\n",
    "    lists_dir = glob(label_path+'*') #label file directorie list\n",
    "    lists_dir.sort()\n",
    "\n",
    "    lists_name = [f for f in os.listdir(label_path) if not f.startswith('.')]   #label file list. Neglect hidden files\n",
    "    lists_name.sort()\n",
    "    lists_name\n",
    "\n",
    "    marking = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "\n",
    "    for i in range(len(lists_dir)):\n",
    "        xlsx = pd.read_excel(lists_dir[i], header = None)    \n",
    "        temp = pd.DataFrame(columns=['slice', 'x', 'y', 'class'])\n",
    "        temp2 = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "        for k in range(xlsx.shape[0]):\n",
    "            temp.loc[k] = list(xlsx.loc[k])\n",
    "        temp = temp.drop_duplicates(['x','y'], keep = 'first')       #drop out repeated 'x','y' values(= drop out same cmb) -\n",
    "        temp = temp.sort_values(by = 'slice',ignore_index=True)\n",
    "        for k in range(temp.shape[0]):\n",
    "            temp2.loc[k, 'image_id'] = lists_name[i].replace('.xlsx','')+ '_'+ str(temp.loc[k,'slice'])\n",
    "            temp2.loc[k, 'x'] = temp.loc[k,'x']-44    #Convert coordinates 512X448 -> 360X360\n",
    "            temp2.loc[k, 'y'] = temp.loc[k,'y']-76\n",
    "            temp2.loc[k, 'w'] = 20\n",
    "            temp2.loc[k, 'h'] = 20\n",
    "        marking = pd.concat([marking, temp2], ignore_index=True)\n",
    "    return marking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the table for 'whole' test set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_whole_marking_axial(label_path,IMAGE_ROOT_PATH, marking_test):\n",
    "    lists_name = [f for f in os.listdir(label_path) if not f.startswith('.')]   #label file list. Neglect hidden files\n",
    "    lists_name.sort()\n",
    "    marking_test_all = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "\n",
    "    for i in range(len(lists_name)):\n",
    "\n",
    "        patient_name = lists_name[i].replace('.xlsx','')\n",
    "        im_list = [path.split('/')[-1][:-4] for path in glob(f'{IMAGE_ROOT_PATH}/{patient_name}_*.png')]\n",
    "        im_list = ns.natsorted(im_list)\n",
    "\n",
    "        temp2 = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "        temp2['image_id'] = im_list\n",
    "        temp2['x'] = 1\n",
    "        temp2['y'] = 1\n",
    "        temp2['w'] = 1\n",
    "        temp2['h'] = 1\n",
    "        marking_test_all = pd.concat([marking_test_all, temp2], ignore_index=True)\n",
    "\n",
    "    for i in range(len(marking_test)):     # fill the CMBs labels\n",
    "        index_num = marking_test_all.index[marking_test_all['image_id']==marking_test.loc[i,'image_id']].tolist()\n",
    "        if marking_test_all.loc[index_num[0],'x'] == 1:     #if it is first CMB on certain slice\n",
    "            marking_test_all.loc[index_num[0]] = marking_test.loc[i]\n",
    "        else:   #not first CMB on certain slice\n",
    "            temp1 = marking_test_all[marking_test_all.index < index_num[0]]\n",
    "            temp2 = marking_test_all[marking_test_all.index >= index_num[0]]\n",
    "            marking_test_all = temp1.append(marking_test.loc[i],ignore_index=True).append(temp2, ignore_index=True)\n",
    "    return marking_test_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizes the image and specifies the parameters for the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_transforms_axial():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever_cmbs:\n",
    "\n",
    "    def __init__(self, marking, image_ids, image_root_path, transforms=None, test=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = image_ids\n",
    "        self.marking = marking\n",
    "        self.transforms = transforms\n",
    "        self.test = test\n",
    "        self.image_root_path  = image_root_path\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "    \n",
    "        image, boxes = self.load_image_and_boxes(index)\n",
    "        \n",
    "        # there is only one class\n",
    "        labels = torch.ones((boxes.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "\n",
    "\n",
    "        if self.transforms:\n",
    "            for i in range(10):\n",
    "                sample = self.transforms(**{\n",
    "                    'image': image,\n",
    "                    'bboxes': target['boxes'],\n",
    "                    'labels': labels\n",
    "                })\n",
    "                if len(sample['bboxes']) > 0:       \n",
    "                    image = sample['image']\n",
    "                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  #yxyx: be warning\n",
    "                    break\n",
    "        else:\n",
    "            image = torch.tensor(image)\n",
    "            target['boxes'] = torch.tensor(boxes)\n",
    "\n",
    "        return image, target, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def load_image_and_boxes(self, index):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = cv2.imread(f'{self.image_root_path}/{image_id}.png', cv2.IMREAD_UNCHANGED)    #get 16bit images\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)    #Convert BGR -> RGB\n",
    "        image/=65535.0\n",
    "        records = self.marking[self.marking['image_id'] == image_id]\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values \n",
    "        boxes[:, 0] = boxes[:, 0] - boxes[:, 2]/2         #transforms to left top corner&right bottom corner\n",
    "        boxes[:, 1] = boxes[:, 1] - boxes[:, 3]/2\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        return image, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "    \n",
    "def euclid_dist(t1, t2):\n",
    "    return np.sqrt(((t1-t2)**2).sum(axis = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replaces occurrences of a substring from the right side of the original string with a new substring, up to a specified count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceRight(original, old, new, count_right):\n",
    "    repeat=0\n",
    "    text = original\n",
    "    old_len = len(old)\n",
    "    \n",
    "    count_find = original.count(old)\n",
    "    if count_right > count_find: \n",
    "        repeat = count_find\n",
    "    else :\n",
    "        repeat = count_right\n",
    "\n",
    "    while(repeat):\n",
    "      find_index = text.rfind(old)\n",
    "      text = text[:find_index] + new + text[find_index+old_len:]\n",
    "\n",
    "      repeat -= 1\n",
    "      \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths for training and validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_path = '/data/labels/train/'\n",
    "val_label_path = '/data/labels/validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the markings of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/data/labels/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m marking_train \u001b[38;5;241m=\u001b[39m \u001b[43mget_axial_marking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_label_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m marking_val \u001b[38;5;241m=\u001b[39m get_axial_marking(val_label_path)\n",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m, in \u001b[0;36mget_axial_marking\u001b[1;34m(label_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m lists_dir \u001b[38;5;241m=\u001b[39m glob(label_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m#label file directorie list\u001b[39;00m\n\u001b[0;32m      3\u001b[0m lists_dir\u001b[38;5;241m.\u001b[39msort()\n\u001b[1;32m----> 5\u001b[0m lists_name \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)]   \u001b[38;5;66;03m#label file list. Neglect hidden files\u001b[39;00m\n\u001b[0;32m      6\u001b[0m lists_name\u001b[38;5;241m.\u001b[39msort()\n\u001b[0;32m      7\u001b[0m lists_name\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/data/labels/train/'"
     ]
    }
   ],
   "source": [
    "marking_train = get_axial_marking(train_label_path)\n",
    "marking_val = get_axial_marking(val_label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the dataset that will be used for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_aug = DatasetRetriever_cmbs(\n",
    "    image_ids=np.array(marking_train['image_id']),  #array with image_ids\n",
    "    marking=marking_train, \n",
    "    transforms=get_train_transforms(),\n",
    "    test=False,\n",
    ")\n",
    "\n",
    "validation_dataset = DatasetRetriever_cmbs(\n",
    "    image_ids=np.array(marking_val['image_id']),\n",
    "    marking=marking_val,\n",
    "    transforms=get_valid_transforms(),\n",
    "    test=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 20\n",
    "    batch_size = 1\n",
    "    n_epochs = 10\n",
    "    lr = 0.0001\n",
    "\n",
    "    folder = 'Model_Save(Axial)_D7'\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False # do scheduler.step after optimizer.step\n",
    "    epoch_scheduler = False\n",
    "    validation_scheduler = True # do scheduler.step after validation stage loss -> For scheduler 'ReduceLROnPlateau'\n",
    "    \n",
    "#     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "#     scheduler_params = dict(\n",
    "#         max_lr=0.001,\n",
    "#         epochs=n_epochs,\n",
    "#         steps_per_epoch=2*int(len(train_dataset_aug) / batch_size),\n",
    "#         pct_start=0.31,\n",
    "#         anneal_strategy='cos', \n",
    "#         final_div_factor=10**4\n",
    "#     )\n",
    "\n",
    "#     SchedulerClass = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
    "#     scheduler_params = dict(\n",
    "#         T_0=5,        # Number of iterations for the first restart.\n",
    "#         T_mult=2,    \n",
    "#         eta_min=0.00004,\n",
    "#         last_epoch=-1, \n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "#     SchedulerClass = torch.optim.lr_scheduler.ExponentialLR\n",
    "#     scheduler_params = dict(\n",
    "#         gamma = 0.7\n",
    "#     )\n",
    "\n",
    "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    scheduler_params = dict(\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=1,\n",
    "        verbose=False, \n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0, \n",
    "        min_lr=0,\n",
    "        eps=1e-08\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "\n",
    "    net = get_net()\n",
    "    device = torch.device(device_num)\n",
    "    net.to(device)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset_aug,\n",
    "        batch_size=TrainGlobalConfig.batch_size,     \n",
    "        sampler=RandomSampler(train_dataset_aug),\n",
    "        pin_memory=False,\n",
    "        drop_last=False,   #drop last one for having same batch size\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        validation_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(validation_dataset),\n",
    "        pin_memory=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "    best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val = fitter.fit(train_loader, val_loader)\n",
    "    \n",
    "    return best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will return the efficientdet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get the weights:\n",
    "\n",
    "1. Go to: https://github.com/rwightman/efficientdet-pytorch/releases\n",
    "2. Look for Weights in the bottom\n",
    "3. Find \"efficientdet_d7-f05bf714.pth\"\n",
    "4. Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    config = get_efficientdet_config('tf_efficientdet_d7')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    checkpoint = torch.load('iefficientdet_d7-f05bf714.pth')\n",
    "    net.load_state_dict(checkpoint)\n",
    "\n",
    "    config.num_classes = 1\n",
    "    config.image_size = 512  #D0\n",
    "\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes) #Use default batchnorm\n",
    "    \n",
    "    return DetBenchTrain(net, config)\n",
    "\n",
    "best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val = run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_path = 'data/labels/test/'\n",
    "IMAGE_ROOT_PATH_AXIAL = 'data/images/axial/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth annotations for CMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Temp\\ipykernel_16828\\2908703177.py:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  numbers_axial = re.findall(\"\\d+\", image_id)\n",
      "C:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Temp\\ipykernel_16828\\2908703177.py:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  numbers_axial = re.findall(\"\\d+\", image_id)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'marking_test_all_axial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m         marking_cd_gt_axial \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([marking_cd_gt_axial, temp], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m marking_cd_gt_axial\n\u001b[1;32m---> 18\u001b[0m num_cmbs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mmarking_test_all_axial\u001b[49m[marking_test_all_axial[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'marking_test_all_axial' is not defined"
     ]
    }
   ],
   "source": [
    "def make_marking_cd_gt_axial(marking_test_axial):\n",
    "    marking_cd_gt_axial = pd.DataFrame(columns=['patient_id', 's', 'x', 'y'])\n",
    "    for i in range(len(marking_test_axial)):\n",
    "        image_id = marking_test_axial.loc[i]['image_id']\n",
    "        numbers_axial = re.findall(\"\\d+\", image_id)\n",
    "        slice_num_axial = int(numbers_axial[-1])\n",
    "        patient_id = replaceRight(image_id, '_'+str(slice_num_axial), '', 1)\n",
    "\n",
    "        x = 512*marking_test_axial.loc[i]['x']/360\n",
    "        y = 512*marking_test_axial.loc[i]['y']/360    \n",
    "\n",
    "        temp = pd.DataFrame(columns=['patient_id', 's', 'x', 'y'])\n",
    "        temp.loc[0] = [patient_id, slice_num_axial, x, y]\n",
    "        marking_cd_gt_axial = pd.concat([marking_cd_gt_axial, temp], ignore_index=True)\n",
    "\n",
    "    return marking_cd_gt_axial\n",
    "\n",
    "num_cmbs=len(marking_test_all_axial[marking_test_all_axial['y']!=1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions in Axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_axial(images, score_threshold=0.29): #Confidence score...? Default 0.22\n",
    "    device = torch.device(device_num)\n",
    "    images = torch.stack(images).to(device).float()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        det = net_axial(images, torch.tensor([1]*images.shape[0]).float().to(device))\n",
    "        for i in range(images.shape[0]):\n",
    "            boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "            scores = det[i].detach().cpu().numpy()[:,4]\n",
    "            indexes = np.where(scores > score_threshold)[0]\n",
    "            boxes = boxes[indexes]\n",
    "            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "            predictions.append({\n",
    "                'boxes': boxes[indexes],\n",
    "                'scores': scores[indexes],\n",
    "            })\n",
    "    return [predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Boxes Fusion (WBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wbf_axial(predictions, image_index, image_size=512, iou_thr=0.45, skip_box_thr=0, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting False Positives and True Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fptp(marking_cd_gt_patient, marking_cd_gt, marking_cd_slice, slice_num, patient_name, x, y):\n",
    "    #tp_candi -> near_gt: x,y cordi of ground truth from slices adjacent to predicting slice\n",
    "    #fp_candi -> near_pd: x,y cordi of predicted boxed from slices adjacent to predicting slice\n",
    "    #near_gt: ground truths (x, y cordi info) in near slices (upper and lower) from current images  \n",
    "    #near_pd: detections (slice, x, y cordi info) in near slices (only upper) from current images\n",
    "    global fp \n",
    "    global fp_count\n",
    "    global tp \n",
    "    global tp_count\n",
    "    \n",
    "    near_gt = marking_cd_gt_patient.loc[abs(slice_num-marking_cd_gt['s'])<5][['x','y']].to_numpy(dtype=float) #GT adjacent to prediction\n",
    "    near_pd = marking_cd_slice.loc[(slice_num-marking_cd_slice['s']<5)&(marking_cd_slice['patient_id']==patient_name)][['x','y']].to_numpy(dtype=float)\n",
    "\n",
    "    #count fp \n",
    "    if near_gt.shape[0]!=0:  #if predicted slice is adjacent to GT slices\n",
    "        dists_from_gt_list = euclid_dist([x, y], near_gt)\n",
    "        if dists_from_gt_list.min() > 20: #if the prediction is far from gt->FP in x, y cordi\n",
    "            #check whether the fp is consecutive or not\n",
    "            if near_pd.shape[0]!= 0: #\n",
    "                if euclid_dist([x, y], near_pd).min() > 10: #not consecutive detection.\n",
    "                    fp_count +=1\n",
    "                    fp = np.append(fp, np.array([[patient_name, slice_num, x, y, 0]]), axis=0)\n",
    "            else:\n",
    "                fp_count +=1\n",
    "                fp = np.append(fp, np.array([[patient_name, slice_num, x, y, 1]]), axis=0)\n",
    "        \n",
    "        else: #if the prediction is close to gt -> TP\n",
    "            for q in range(len(near_gt)):\n",
    "                near_gt_index = marking_cd_gt_patient.loc[(marking_cd_gt['x']==near_gt[q][0]) & (marking_cd_gt['y']==near_gt[q][1])].index[0]\n",
    "                if dists_from_gt_list[q] < 30 and marking_cd_gt_patient.loc[near_gt_index, 'state'] != 1: # if the gt is close to prediction and not detected.\n",
    "                    #check whether the tp is consecutive or not\n",
    "                    if near_pd.shape[0] != 0: #There are dets in the near slices \n",
    "                        if euclid_dist([x, y], near_pd).min() > 5: #there is no close x, y det -> not consecutive. 5\n",
    "                            tp_count += 1\n",
    "                            tp = np.append(tp, np.array([[patient_name, slice_num, x, y, 0]]), axis=0)\n",
    "                            marking_cd_gt_patient.loc[near_gt_index, 'state'] = 1\n",
    "                    else:\n",
    "                        tp_count += 1\n",
    "                        tp = np.append(tp, np.array([[patient_name, slice_num, x, y, 1]]), axis=0)\n",
    "                        marking_cd_gt_patient.loc[near_gt_index, 'state'] = 1\n",
    "                        \n",
    "    else:   #Predicted slice is not adjacent to that of GTs               \n",
    "        if i == 0:   #first slice\n",
    "            fp_count +=1\n",
    "            fp = np.append(fp, np.array([[patient_name, slice_num, x, y, 2]]), axis=0)\n",
    "        else:  \n",
    "            if near_pd.shape[0] != 0:\n",
    "                if euclid_dist([x, y], near_pd).min() > 10:\n",
    "                    fp_count +=1\n",
    "                    fp = np.append(fp, np.array([[patient_name, slice_num, x, y, 3]]), axis=0)\n",
    "            else:\n",
    "                fp_count +=1\n",
    "                fp = np.append(fp, np.array([[patient_name, slice_num, x, y, 4]]), axis=0)\n",
    "    return fp, fp_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Sure pero sabi ni ChatGPT pang evaluate daw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d3')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    \n",
    "    config.num_classes = 1\n",
    "    config.image_size=512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01)) # Configures the classification head of the model\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device_num)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = DetBenchEval(net, config)\n",
    "    net.eval();\n",
    "    device = torch.device(device_num)\n",
    "    return net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_axial = load_net('../Model/best-checkpoint.bin')\n",
    "net_sagittal = load_net('../Model/best-checkpoint.bin')\n",
    "net_coronal = load_net('../Model/best-checkpoint.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_all_axial = DatasetRetriever_cmbs(\n",
    "    image_ids=np.array(marking_test_all_axial['image_id']),\n",
    "    marking=marking_test_all_axial,\n",
    "    transforms=get_valid_transforms_axial(),\n",
    "    test=False,\n",
    "    image_root_path = IMAGE_ROOT_PATH_AXIAL,\n",
    ")\n",
    "\n",
    "test_data_loader_all_axial = DataLoader(\n",
    "    test_dataset_all_axial,\n",
    "    batch_size=32,     #batchsize = 4\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_axial(images, score_threshold=0.29): #Confidence score...? Default 0.22\n",
    "    device = torch.device(device_num)\n",
    "    images = torch.stack(images).to(device).float()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        det = net_axial(images, torch.tensor([1]*images.shape[0]).float().to(device))\n",
    "        for i in range(images.shape[0]):\n",
    "            boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "            scores = det[i].detach().cpu().numpy()[:,4]\n",
    "            indexes = np.where(scores > score_threshold)[0]\n",
    "            boxes = boxes[indexes]\n",
    "            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "            predictions.append({\n",
    "                'boxes': boxes[indexes],\n",
    "                'scores': scores[indexes],\n",
    "            })\n",
    "    return [predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wbf_axial(predictions, image_index, image_size=512, iou_thr=0.45, skip_box_thr=0, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

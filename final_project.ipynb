{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# %pip install ensemble_boxes\n",
    "# %pip install albumentations\n",
    "# %pip install effdet\n",
    "# %pip install natsort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from ensemble_boxes import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import natsort as ns\n",
    "import re\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0+cu118\n",
      "CUDA available: True\n",
      "Number of CUDA devices: 1\n",
      "CUDA device name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 #any constant\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change into the device name of your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_num = 'NVIDIA GeForce GTX 1650'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pretrained EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d3')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    \n",
    "    config.num_classes = 1\n",
    "    config.image_size=512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device_num)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = DetBenchEval(net, config)\n",
    "    net.eval()\n",
    "    device = torch.device(device_num)\n",
    "    return net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Axial marking from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axial_marking(label_path):\n",
    "    lists_dir = glob(label_path+'*') #label file directorie list\n",
    "    lists_dir.sort()\n",
    "\n",
    "    lists_name = [f for f in os.listdir(label_path) if not f.startswith('.')]   #label file list. Neglect hidden files\n",
    "    lists_name.sort()\n",
    "    lists_name\n",
    "\n",
    "    marking = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "\n",
    "    for i in range(len(lists_dir)):\n",
    "        xlsx = pd.read_excel(lists_dir[i], header = None)    \n",
    "        temp = pd.DataFrame(columns=['slice', 'x', 'y', 'class'])\n",
    "        temp2 = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "        for k in range(xlsx.shape[0]):\n",
    "            temp.loc[k] = list(xlsx.loc[k])\n",
    "        temp = temp.drop_duplicates(['x','y'], keep = 'first')       #drop out repeated 'x','y' values(= drop out same cmb) -\n",
    "        temp = temp.sort_values(by = 'slice',ignore_index=True)\n",
    "        for k in range(temp.shape[0]):\n",
    "            temp2.loc[k, 'image_id'] = lists_name[i].replace('.xlsx','')+ '_'+ str(temp.loc[k,'slice'])\n",
    "            temp2.loc[k, 'x'] = temp.loc[k,'x']-44    #Convert coordinates 512X448 -> 360X360\n",
    "            temp2.loc[k, 'y'] = temp.loc[k,'y']-76\n",
    "            temp2.loc[k, 'w'] = 20\n",
    "            temp2.loc[k, 'h'] = 20\n",
    "        marking = pd.concat([marking, temp2], ignore_index=True)\n",
    "    return marking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the table for 'whole' test set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_whole_marking_axial(label_path,IMAGE_ROOT_PATH, marking_test):\n",
    "    lists_name = [f for f in os.listdir(label_path) if not f.startswith('.')]   #label file list. Neglect hidden files\n",
    "    lists_name.sort()\n",
    "    marking_test_all = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "\n",
    "    for i in range(len(lists_name)):\n",
    "\n",
    "        patient_name = lists_name[i].replace('.xlsx','')\n",
    "        im_list = [path.split('/')[-1][:-4] for path in glob(f'{IMAGE_ROOT_PATH}/{patient_name}_*.png')]\n",
    "        im_list = ns.natsorted(im_list)\n",
    "\n",
    "        temp2 = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "        temp2['image_id'] = im_list\n",
    "        temp2['x'] = 1\n",
    "        temp2['y'] = 1\n",
    "        temp2['w'] = 1\n",
    "        temp2['h'] = 1\n",
    "        marking_test_all = pd.concat([marking_test_all, temp2], ignore_index=True)\n",
    "\n",
    "    for i in range(len(marking_test)):     # fill the CMBs labels\n",
    "        index_num = marking_test_all.index[marking_test_all['image_id']==marking_test.loc[i,'image_id']].tolist()\n",
    "        if marking_test_all.loc[index_num[0],'x'] == 1:     #if it is first CMB on certain slice\n",
    "            marking_test_all.loc[index_num[0]] = marking_test.loc[i]\n",
    "        else:   #not first CMB on certain slice\n",
    "            temp1 = marking_test_all[marking_test_all.index < index_num[0]]\n",
    "            temp2 = marking_test_all[marking_test_all.index >= index_num[0]]\n",
    "            marking_test_all = temp1.append(marking_test.loc[i],ignore_index=True).append(temp2, ignore_index=True)\n",
    "    return marking_test_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizes the image and specifies the parameters for the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_transforms_axial():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever_cmbs:\n",
    "\n",
    "    def __init__(self, marking, image_ids, image_root_path, transforms=None, test=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = image_ids\n",
    "        self.marking = marking\n",
    "        self.transforms = transforms\n",
    "        self.test = test\n",
    "        self.image_root_path  = image_root_path\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "    \n",
    "        image, boxes = self.load_image_and_boxes(index)\n",
    "        \n",
    "        # there is only one class\n",
    "        labels = torch.ones((boxes.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "\n",
    "\n",
    "        if self.transforms:\n",
    "            for i in range(10):\n",
    "                sample = self.transforms(**{\n",
    "                    'image': image,\n",
    "                    'bboxes': target['boxes'],\n",
    "                    'labels': labels\n",
    "                })\n",
    "                if len(sample['bboxes']) > 0:       \n",
    "                    image = sample['image']\n",
    "                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  #yxyx: be warning\n",
    "                    break\n",
    "        else:\n",
    "            image = torch.tensor(image)\n",
    "            target['boxes'] = torch.tensor(boxes)\n",
    "\n",
    "        return image, target, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def load_image_and_boxes(self, index):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = cv2.imread(f'{self.image_root_path}/{image_id}.png', cv2.IMREAD_UNCHANGED)    #get 16bit images\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)    #Convert BGR -> RGB\n",
    "        image/=65535.0\n",
    "        records = self.marking[self.marking['image_id'] == image_id]\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values \n",
    "        boxes[:, 0] = boxes[:, 0] - boxes[:, 2]/2         #transforms to left top corner&right bottom corner\n",
    "        boxes[:, 1] = boxes[:, 1] - boxes[:, 3]/2\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        return image, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "    \n",
    "def euclid_dist(t1, t2):\n",
    "    return np.sqrt(((t1-t2)**2).sum(axis = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replaces occurrences of a substring from the right side of the original string with a new substring, up to a specified count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceRight(original, old, new, count_right):\n",
    "    repeat=0\n",
    "    text = original\n",
    "    old_len = len(old)\n",
    "    \n",
    "    count_find = original.count(old)\n",
    "    if count_right > count_find: \n",
    "        repeat = count_find\n",
    "    else :\n",
    "        repeat = count_right\n",
    "\n",
    "    while(repeat):\n",
    "      find_index = text.rfind(old)\n",
    "      text = text[:find_index] + new + text[find_index+old_len:]\n",
    "\n",
    "      repeat -= 1\n",
    "      \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths for training and validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label_path = '/data/labels/train/'\n",
    "val_label_path = '/data/labels/validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the markings of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marking_train = get_axial_marking(train_label_path)\n",
    "marking_val = get_axial_marking(val_label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the dataset that will be used for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_aug = DatasetRetriever_cmbs(\n",
    "    image_ids=np.array(marking_train['image_id']),  #array with image_ids\n",
    "    marking=marking_train, \n",
    "    transforms=get_train_transforms(),\n",
    "    test=False,\n",
    ")\n",
    "\n",
    "validation_dataset = DatasetRetriever_cmbs(\n",
    "    image_ids=np.array(marking_val['image_id']),\n",
    "    marking=marking_val,\n",
    "    transforms=get_valid_transforms(),\n",
    "    test=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 20\n",
    "    batch_size = 1\n",
    "    n_epochs = 10\n",
    "    lr = 0.0001\n",
    "\n",
    "    folder = 'Model_Save(Axial)_D7'\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False # do scheduler.step after optimizer.step\n",
    "    epoch_scheduler = False\n",
    "    validation_scheduler = True # do scheduler.step after validation stage loss -> For scheduler 'ReduceLROnPlateau'\n",
    "    \n",
    "#     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "#     scheduler_params = dict(\n",
    "#         max_lr=0.001,\n",
    "#         epochs=n_epochs,\n",
    "#         steps_per_epoch=2*int(len(train_dataset_aug) / batch_size),\n",
    "#         pct_start=0.31,\n",
    "#         anneal_strategy='cos', \n",
    "#         final_div_factor=10**4\n",
    "#     )\n",
    "\n",
    "#     SchedulerClass = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
    "#     scheduler_params = dict(\n",
    "#         T_0=5,        # Number of iterations for the first restart.\n",
    "#         T_mult=2,    \n",
    "#         eta_min=0.00004,\n",
    "#         last_epoch=-1, \n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "#     SchedulerClass = torch.optim.lr_scheduler.ExponentialLR\n",
    "#     scheduler_params = dict(\n",
    "#         gamma = 0.7\n",
    "#     )\n",
    "\n",
    "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    scheduler_params = dict(\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=1,\n",
    "        verbose=False, \n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0, \n",
    "        min_lr=0,\n",
    "        eps=1e-08\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "\n",
    "    net = get_net()\n",
    "    device = torch.device(device_num)\n",
    "    net.to(device)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset_aug,\n",
    "        batch_size=TrainGlobalConfig.batch_size,     \n",
    "        sampler=RandomSampler(train_dataset_aug),\n",
    "        pin_memory=False,\n",
    "        drop_last=False,   #drop last one for having same batch size\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        validation_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(validation_dataset),\n",
    "        pin_memory=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "    best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val = fitter.fit(train_loader, val_loader)\n",
    "    \n",
    "    return best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will return the efficientdet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get the weights:\n",
    "\n",
    "1. Go to: https://github.com/rwightman/efficientdet-pytorch/releases\n",
    "2. Look for Weights in the bottom\n",
    "3. Find \"efficientdet_d7-f05bf714.pth\"\n",
    "4. Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_net():\n",
    "    config = get_efficientdet_config('tf_efficientdet_d7')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    checkpoint = torch.load('iefficientdet_d7-f05bf714.pth')\n",
    "    net.load_state_dict(checkpoint)\n",
    "\n",
    "    config.num_classes = 1\n",
    "    config.image_size = 512  #D0\n",
    "\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes) #Use default batchnorm\n",
    "    \n",
    "    return DetBenchTrain(net, config)\n",
    "\n",
    "# best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val = run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_path = 'data/labels/test/'\n",
    "IMAGE_ROOT_PATH_AXIAL = 'data/images/axial/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_marking_cd_gt_axial(marking_test_axial):\n",
    "    marking_cd_gt_axial = pd.DataFrame(columns=['patient_id', 's', 'x', 'y'])\n",
    "    for i in range(len(marking_test_axial)):\n",
    "        image_id = marking_test_axial.loc[i]['image_id']\n",
    "        numbers_axial = re.findall(\"\\d+\", image_id)\n",
    "        slice_num_axial = int(numbers_axial[-1])\n",
    "        patient_id = replaceRight(image_id, '_'+str(slice_num_axial), '', 1)\n",
    "\n",
    "        x = 512*marking_test_axial.loc[i]['x']/360\n",
    "        y = 512*marking_test_axial.loc[i]['y']/360    \n",
    "\n",
    "        temp = pd.DataFrame(columns=['patient_id', 's', 'x', 'y'])\n",
    "        temp.loc[0] = [patient_id, slice_num_axial, x, y]\n",
    "        marking_cd_gt_axial = pd.concat([marking_cd_gt_axial, temp], ignore_index=True)\n",
    "\n",
    "    return marking_cd_gt_axial\n",
    "\n",
    "num_cmbs=len(marking_test_all_axial[marking_test_all_axial['y']!=1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "# %pip install ensemble_boxes\n",
    "# %pip install albumentations\n",
    "# %pip install effdet\n",
    "# %pip install natsort\n",
    "#%pip install nibabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from ensemble_boxes import *\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import cv2\n",
    "import gc\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import natsort as ns\n",
    "import re\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain, DetBenchPredict\n",
    "from effdet.efficientdet import HeadNet\n",
    "from torch.utils.data import Dataset\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For testing only\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations import Compose, Normalize, Resize, BboxParams\n",
    "from omegaconf import OmegaConf\n",
    "# from fitter import Fitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\T'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\T'\n",
      "C:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Temp\\ipykernel_29192\\1612283650.py:3: SyntaxWarning: invalid escape sequence '\\T'\n",
      "  testing_label_relative = 'VALDO_Dataset\\Task2'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cohort1': ['sub-101',\n",
       "  'sub-102',\n",
       "  'sub-103',\n",
       "  'sub-104',\n",
       "  'sub-105',\n",
       "  'sub-106',\n",
       "  'sub-107',\n",
       "  'sub-108',\n",
       "  'sub-109',\n",
       "  'sub-110',\n",
       "  'sub-111'],\n",
       " 'cohort2': ['sub-201',\n",
       "  'sub-202',\n",
       "  'sub-203',\n",
       "  'sub-204',\n",
       "  'sub-205',\n",
       "  'sub-206',\n",
       "  'sub-207',\n",
       "  'sub-208',\n",
       "  'sub-209',\n",
       "  'sub-210',\n",
       "  'sub-211',\n",
       "  'sub-212',\n",
       "  'sub-213',\n",
       "  'sub-214',\n",
       "  'sub-215',\n",
       "  'sub-216',\n",
       "  'sub-217',\n",
       "  'sub-218',\n",
       "  'sub-219',\n",
       "  'sub-220',\n",
       "  'sub-221',\n",
       "  'sub-222',\n",
       "  'sub-223',\n",
       "  'sub-224',\n",
       "  'sub-225',\n",
       "  'sub-226',\n",
       "  'sub-227',\n",
       "  'sub-228',\n",
       "  'sub-229',\n",
       "  'sub-230',\n",
       "  'sub-231',\n",
       "  'sub-232',\n",
       "  'sub-233',\n",
       "  'sub-234'],\n",
       " 'cohort3': ['sub-301',\n",
       "  'sub-302',\n",
       "  'sub-303',\n",
       "  'sub-304',\n",
       "  'sub-305',\n",
       "  'sub-306',\n",
       "  'sub-307',\n",
       "  'sub-308',\n",
       "  'sub-309',\n",
       "  'sub-310',\n",
       "  'sub-311',\n",
       "  'sub-312',\n",
       "  'sub-313',\n",
       "  'sub-314',\n",
       "  'sub-315',\n",
       "  'sub-316',\n",
       "  'sub-317',\n",
       "  'sub-318',\n",
       "  'sub-319',\n",
       "  'sub-320',\n",
       "  'sub-321',\n",
       "  'sub-322',\n",
       "  'sub-323',\n",
       "  'sub-324',\n",
       "  'sub-325',\n",
       "  'sub-326',\n",
       "  'sub-327']}"
      ]
     },
     "execution_count": 725,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "testing_label_relative = 'VALDO_Dataset\\Task2'\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "two_directories_up = os.path.abspath(os.path.join(current_directory, \"../\"))\n",
    "\n",
    "# Combine the current directory with the relative path\n",
    "testing_label_absolute = os.path.join(two_directories_up, testing_label_relative)\n",
    "\n",
    "folders = [item for item in os.listdir(testing_label_absolute) if os.path.isdir(os.path.join(testing_label_absolute, item))]\n",
    "\n",
    "cases = {\"cohort1\": [], \"cohort2\": [], \"cohort3\": []}\n",
    "# Print the list of folders\n",
    "for folder in folders:\n",
    "    if \"sub-1\" in folder:\n",
    "        cases[\"cohort1\"].append(folder)\n",
    "    elif \"sub-2\" in folder:\n",
    "        cases[\"cohort2\"].append(folder)\n",
    "    else:\n",
    "        cases[\"cohort3\"].append(folder)\n",
    "\n",
    "cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lex Zedrick Lorenzo\\Documents\\GitHub\\VALDO_Dataset\\Task2\\sub-101\\sub-101_space-T2S_CMB.nii.gz\n",
      "c:\\Users\\Lex Zedrick Lorenzo\\Documents\\GitHub\\VALDO_Dataset\\Task2\\sub-101\\sub-101_space-T2S_desc-masked_T2S.nii.gz\n"
     ]
    }
   ],
   "source": [
    "cohort1_labels = []\n",
    "cohort1_ids = []\n",
    "for case in cases[\"cohort1\"]:\n",
    "    label = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_CMB.nii.gz\"\n",
    "    id = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_desc-masked_T2S.nii.gz\"\n",
    "    cohort1_labels.append(label)\n",
    "    cohort1_ids.append(id)\n",
    "# print(\"Label:\", cohort1_labels, cohort1_labels.__len__())\n",
    "# print(\"Ids:\", cohort1_ids, cohort1_ids.__len__())\n",
    "\n",
    "cohort2_labels = []\n",
    "cohort2_ids = []\n",
    "for case in cases[\"cohort2\"]:\n",
    "    label = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_CMB.nii.gz\"\n",
    "    id = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_desc-masked_T2S.nii.gz\"\n",
    "    cohort2_labels.append(label)\n",
    "    cohort2_ids.append(id)\n",
    "# print(\"Label:\", cohort2_labels, cohort2_labels.__len__())\n",
    "# print(\"Ids:\", cohort2_ids, cohort2_ids.__len__())\n",
    "\n",
    "cohort3_labels = []\n",
    "cohort3_ids = []\n",
    "for case in cases[\"cohort3\"]:\n",
    "    label = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_CMB.nii.gz\"\n",
    "    id = f\"{testing_label_absolute}\\\\{case}\\\\{case}_space-T2S_desc-masked_T2S.nii.gz\"\n",
    "    cohort3_labels.append(label)\n",
    "    cohort3_ids.append(id)\n",
    "# print(\"Label:\", cohort3_labels, cohort3_labels.__len__())\n",
    "# print(\"Ids:\", cohort3_ids, cohort3_ids.__len__())\n",
    "\n",
    "all_labels = cohort1_labels + cohort2_labels + cohort3_labels\n",
    "all_ids = cohort1_ids + cohort2_ids + cohort3_ids\n",
    "\n",
    "\n",
    "\n",
    "print(all_labels[0])\n",
    "print(all_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-101\\\\sub-101_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-102\\\\sub-102_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-103\\\\sub-103_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-104\\\\sub-104_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-105\\\\sub-105_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-106\\\\sub-106_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-107\\\\sub-107_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-108\\\\sub-108_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-109\\\\sub-109_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-110\\\\sub-110_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-111\\\\sub-111_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-201\\\\sub-201_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-202\\\\sub-202_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-203\\\\sub-203_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-204\\\\sub-204_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-205\\\\sub-205_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-206\\\\sub-206_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-207\\\\sub-207_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-208\\\\sub-208_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-209\\\\sub-209_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-210\\\\sub-210_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-211\\\\sub-211_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-212\\\\sub-212_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-213\\\\sub-213_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-214\\\\sub-214_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-215\\\\sub-215_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-216\\\\sub-216_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-217\\\\sub-217_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-218\\\\sub-218_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-219\\\\sub-219_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-220\\\\sub-220_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-221\\\\sub-221_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-222\\\\sub-222_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-223\\\\sub-223_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-224\\\\sub-224_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-225\\\\sub-225_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-226\\\\sub-226_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-227\\\\sub-227_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-228\\\\sub-228_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-229\\\\sub-229_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-230\\\\sub-230_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-231\\\\sub-231_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-232\\\\sub-232_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-233\\\\sub-233_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-234\\\\sub-234_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-301\\\\sub-301_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-302\\\\sub-302_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-303\\\\sub-303_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-304\\\\sub-304_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-305\\\\sub-305_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-306\\\\sub-306_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-307\\\\sub-307_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-308\\\\sub-308_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-309\\\\sub-309_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-310\\\\sub-310_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-311\\\\sub-311_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-312\\\\sub-312_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-313\\\\sub-313_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-314\\\\sub-314_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-315\\\\sub-315_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-316\\\\sub-316_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-317\\\\sub-317_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-318\\\\sub-318_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-319\\\\sub-319_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-320\\\\sub-320_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-321\\\\sub-321_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-322\\\\sub-322_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-323\\\\sub-323_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-324\\\\sub-324_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-325\\\\sub-325_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-326\\\\sub-326_space-T2S_CMB.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-327\\\\sub-327_space-T2S_CMB.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-101\\\\sub-101_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-102\\\\sub-102_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-103\\\\sub-103_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-104\\\\sub-104_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-105\\\\sub-105_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-106\\\\sub-106_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-107\\\\sub-107_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-108\\\\sub-108_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-109\\\\sub-109_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-110\\\\sub-110_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-111\\\\sub-111_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-201\\\\sub-201_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-202\\\\sub-202_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-203\\\\sub-203_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-204\\\\sub-204_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-205\\\\sub-205_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-206\\\\sub-206_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-207\\\\sub-207_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-208\\\\sub-208_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-209\\\\sub-209_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-210\\\\sub-210_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-211\\\\sub-211_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-212\\\\sub-212_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-213\\\\sub-213_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-214\\\\sub-214_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-215\\\\sub-215_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-216\\\\sub-216_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-217\\\\sub-217_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-218\\\\sub-218_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-219\\\\sub-219_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-220\\\\sub-220_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-221\\\\sub-221_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-222\\\\sub-222_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-223\\\\sub-223_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-224\\\\sub-224_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-225\\\\sub-225_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-226\\\\sub-226_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-227\\\\sub-227_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-228\\\\sub-228_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-229\\\\sub-229_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-230\\\\sub-230_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-231\\\\sub-231_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-232\\\\sub-232_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-233\\\\sub-233_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-234\\\\sub-234_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-301\\\\sub-301_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-302\\\\sub-302_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-303\\\\sub-303_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-304\\\\sub-304_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-305\\\\sub-305_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-306\\\\sub-306_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-307\\\\sub-307_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-308\\\\sub-308_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-309\\\\sub-309_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-310\\\\sub-310_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-311\\\\sub-311_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-312\\\\sub-312_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-313\\\\sub-313_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-314\\\\sub-314_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-315\\\\sub-315_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-316\\\\sub-316_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-317\\\\sub-317_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-318\\\\sub-318_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-319\\\\sub-319_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-320\\\\sub-320_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-321\\\\sub-321_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-322\\\\sub-322_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-323\\\\sub-323_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-324\\\\sub-324_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-325\\\\sub-325_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-326\\\\sub-326_space-T2S_desc-masked_T2S.nii.gz', 'c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-327\\\\sub-327_space-T2S_desc-masked_T2S.nii.gz']\n"
     ]
    }
   ],
   "source": [
    "print(all_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dataset for VALDO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VALDODataset(Dataset):\n",
    "    def __init__(self, img_paths, ann_paths, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.ann_paths = ann_paths\n",
    "        self.transform = transform\n",
    "\n",
    "        assert len(self.img_paths) == len(self.ann_paths), \"Mismatch between number of images and annotations\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            img_path = self.img_paths[idx]\n",
    "            ann_path = self.ann_paths[idx]\n",
    "\n",
    "            # Load 3D image\n",
    "            img = nib.load(img_path).get_fdata()\n",
    "            img = (img / np.max(img) * 255).astype(np.uint8)\n",
    "            \n",
    "            # Load 3D annotation\n",
    "            ann = nib.load(ann_path).get_fdata()\n",
    "            ann = (ann > 0).astype(np.uint8)  # Ensure mask is binary\n",
    "\n",
    "            slices = []\n",
    "            targets = []\n",
    "\n",
    "            for i in range(img.shape[2]):\n",
    "                img_slice = img[:, :, i]\n",
    "                ann_slice = ann[:, :, i]\n",
    "\n",
    "                img_slice = cv2.merge([img_slice] * 3)  # Convert single-channel to three-channel\n",
    "                boxes = self.extract_bounding_boxes(ann_slice)\n",
    "\n",
    "                if boxes:\n",
    "                    augmented = self.transform(image=img_slice, bboxes=boxes, labels=[1]*len(boxes))\n",
    "                    img_slice = augmented['image']\n",
    "                    boxes = augmented['bboxes']\n",
    "                    labels = augmented['labels']\n",
    "                else:\n",
    "                    augmented = self.transform(image=img_slice, bboxes=[], labels=[])\n",
    "                    img_slice = augmented['image']\n",
    "                    boxes = augmented['bboxes']\n",
    "                    labels = augmented['labels']\n",
    "\n",
    "                target = {\n",
    "                    'boxes': torch.tensor(boxes, dtype=torch.float32),\n",
    "                    'labels': torch.tensor(labels, dtype=torch.int64)\n",
    "                }\n",
    "\n",
    "                slices.append(img_slice)\n",
    "                targets.append(target)\n",
    "\n",
    "            return slices, targets, img_path\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing index {idx}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def extract_bounding_boxes(self, mask):\n",
    "        # Extract bounding boxes from mask\n",
    "        boxes = []\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            # boxes.append([x, y, x + w, y + h])\n",
    "            boxes.append([x, y, x + 20, y + 20])\n",
    "        return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(\n",
    "        [\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    ")\n",
    "\n",
    "dataset = VALDODataset(img_paths=all_ids, ann_paths=all_labels, transform=transform)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of slices: 35\n",
      "Total cases 72\n",
      "Shape of a slice: torch.Size([3, 512, 512]), target: {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([[164., 327., 184., 347.],\n",
      "        [180., 299., 200., 319.]]), 'labels': tensor([1, 1])}\n",
      "{'boxes': tensor([[257., 320., 277., 340.]]), 'labels': tensor([1])}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([[278., 345., 298., 365.]]), 'labels': tensor([1])}\n",
      "{'boxes': tensor([[233., 321., 253., 341.],\n",
      "        [259., 313., 279., 333.]]), 'labels': tensor([1, 1])}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([[155., 188., 175., 208.]]), 'labels': tensor([1])}\n",
      "{'boxes': tensor([[267., 301., 287., 321.],\n",
      "        [264., 294., 284., 314.],\n",
      "        [271., 292., 291., 312.],\n",
      "        [268., 220., 288., 240.],\n",
      "        [259., 216., 279., 236.]]), 'labels': tensor([1, 1, 1, 1, 1])}\n",
      "{'boxes': tensor([[268., 288., 288., 308.],\n",
      "        [271., 226., 291., 246.]]), 'labels': tensor([1, 1])}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([[254., 303., 274., 323.]]), 'labels': tensor([1])}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}\n",
      "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         ...,\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0],\n",
      "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "slices, targets, img_id = dataset[0]\n",
    "print(f\"Number of slices: {len(slices)}\")\n",
    "print('Total cases', dataset.__len__())\n",
    "print(f\"Shape of a slice: {slices[0].shape}, target: {targets[0]}\")\n",
    "\n",
    "for i in targets:\n",
    "    print(i)\n",
    "\n",
    "print(slices[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.3.0+cu118\n",
      "CUDA available: True\n",
      "Number of CUDA devices: 1\n",
      "CUDA device name: NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42 #any constant\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change into the device name of your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_num = torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the pretrained EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d3')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    \n",
    "    config.num_classes = 1\n",
    "    config.image_size=512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device_num)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = DetBenchEval(net, config)\n",
    "    net.eval()\n",
    "    device = torch.device(device_num)\n",
    "    return net.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Axial marking from excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axial_marking(label_path):\n",
    "    lists_dir = glob(label_path+'*') #label file directorie list\n",
    "    lists_dir.sort()\n",
    "\n",
    "    lists_name = [f for f in os.listdir(label_path) if not f.startswith('.')]   #label file list. Neglect hidden files\n",
    "    lists_name.sort()\n",
    "    lists_name\n",
    "\n",
    "    marking = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "\n",
    "    for i in range(len(lists_dir)):\n",
    "        xlsx = pd.read_excel(lists_dir[i], header = None)    \n",
    "        temp = pd.DataFrame(columns=['slice', 'x', 'y', 'class'])\n",
    "        temp2 = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "        for k in range(xlsx.shape[0]):\n",
    "            temp.loc[k] = list(xlsx.loc[k])\n",
    "        temp = temp.drop_duplicates(['x','y'], keep = 'first')       #drop out repeated 'x','y' values(= drop out same cmb) -\n",
    "        temp = temp.sort_values(by = 'slice',ignore_index=True)\n",
    "        for k in range(temp.shape[0]):\n",
    "            temp2.loc[k, 'image_id'] = lists_name[i].replace('.xlsx','')+ '_'+ str(temp.loc[k,'slice'])\n",
    "            temp2.loc[k, 'x'] = temp.loc[k,'x']-44    #Convert coordinates 512X448 -> 360X360\n",
    "            temp2.loc[k, 'y'] = temp.loc[k,'y']-76\n",
    "            temp2.loc[k, 'w'] = 20\n",
    "            temp2.loc[k, 'h'] = 20\n",
    "        marking = pd.concat([marking, temp2], ignore_index=True)\n",
    "    return marking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make the table for 'whole' test set images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_whole_marking_axial(label_path,IMAGE_ROOT_PATH, marking_test):\n",
    "    lists_name = [f for f in os.listdir(label_path) if not f.startswith('.')]   #label file list. Neglect hidden files\n",
    "    lists_name.sort()\n",
    "    marking_test_all = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "\n",
    "    for i in range(len(lists_name)):\n",
    "\n",
    "        patient_name = lists_name[i].replace('.xlsx','')\n",
    "        im_list = [path.split('/')[-1][:-4] for path in glob(f'{IMAGE_ROOT_PATH}/{patient_name}_*.png')]\n",
    "        im_list = ns.natsorted(im_list)\n",
    "\n",
    "        temp2 = pd.DataFrame(columns=['image_id', 'x', 'y', 'w', 'h'])\n",
    "        temp2['image_id'] = im_list\n",
    "        temp2['x'] = 1\n",
    "        temp2['y'] = 1\n",
    "        temp2['w'] = 1\n",
    "        temp2['h'] = 1\n",
    "        marking_test_all = pd.concat([marking_test_all, temp2], ignore_index=True)\n",
    "\n",
    "    for i in range(len(marking_test)):     # fill the CMBs labels\n",
    "        index_num = marking_test_all.index[marking_test_all['image_id']==marking_test.loc[i,'image_id']].tolist()\n",
    "        if marking_test_all.loc[index_num[0],'x'] == 1:     #if it is first CMB on certain slice\n",
    "            marking_test_all.loc[index_num[0]] = marking_test.loc[i]\n",
    "        else:   #not first CMB on certain slice\n",
    "            temp1 = marking_test_all[marking_test_all.index < index_num[0]]\n",
    "            temp2 = marking_test_all[marking_test_all.index >= index_num[0]]\n",
    "            marking_test_all = temp1.append(marking_test.loc[i],ignore_index=True).append(temp2, ignore_index=True)\n",
    "    return marking_test_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resizes the image and specifies the parameters for the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_valid_transforms_axial():\n",
    "    return A.Compose(\n",
    "        [\n",
    "            A.Resize(height=512, width=512, p=1.0),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ], \n",
    "        p=1.0, \n",
    "        bbox_params=A.BboxParams(\n",
    "            format='pascal_voc',\n",
    "            min_area=0, \n",
    "            min_visibility=0,\n",
    "            label_fields=['labels']\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetRetriever_cmbs:\n",
    "\n",
    "    def __init__(self, marking, image_ids, image_root_path, transforms=None, test=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.image_ids = image_ids\n",
    "        self.marking = marking\n",
    "        self.transforms = transforms\n",
    "        self.test = test\n",
    "        self.image_root_path  = image_root_path\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        image_id = self.image_ids[index]\n",
    "    \n",
    "        image, boxes = self.load_image_and_boxes(index)\n",
    "        \n",
    "        # there is only one class\n",
    "        labels = torch.ones((boxes.shape[0],), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target['boxes'] = boxes\n",
    "        target['labels'] = labels\n",
    "        target['image_id'] = torch.tensor([index])\n",
    "\n",
    "\n",
    "        if self.transforms:\n",
    "            for i in range(10):\n",
    "                sample = self.transforms(**{\n",
    "                    'image': image,\n",
    "                    'bboxes': target['boxes'],\n",
    "                    'labels': labels\n",
    "                })\n",
    "                if len(sample['bboxes']) > 0:       \n",
    "                    image = sample['image']\n",
    "                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
    "                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  #yxyx: be warning\n",
    "                    break\n",
    "        else:\n",
    "            image = torch.tensor(image)\n",
    "            target['boxes'] = torch.tensor(boxes)\n",
    "\n",
    "        return image, target, image_id\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return self.image_ids.shape[0]\n",
    "\n",
    "    def load_image_and_boxes(self, index):\n",
    "        image_id = self.image_ids[index]\n",
    "        image = cv2.imread(f'{self.image_root_path}/{image_id}.png', cv2.IMREAD_UNCHANGED)    #get 16bit images\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)    #Convert BGR -> RGB\n",
    "        image/=65535.0\n",
    "        records = self.marking[self.marking['image_id'] == image_id]\n",
    "        boxes = records[['x', 'y', 'w', 'h']].values \n",
    "        boxes[:, 0] = boxes[:, 0] - boxes[:, 2]/2         #transforms to left top corner&right bottom corner\n",
    "        boxes[:, 1] = boxes[:, 1] - boxes[:, 3]/2\n",
    "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
    "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
    "        return image, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def collate_fn(batch):\n",
    "#     return tuple(zip(*batch))\n",
    "\n",
    "def collate_fn(batch):\n",
    "    slices = []\n",
    "    targets = []\n",
    "    img_paths = []\n",
    "\n",
    "    for item in batch:\n",
    "        item_slices, item_targets, item_img_path = item\n",
    "        slices.extend(item_slices)\n",
    "        targets.extend(item_targets)\n",
    "        img_paths.append(item_img_path)\n",
    "\n",
    "    slices = torch.stack(slices)\n",
    "    return slices, targets, img_paths\n",
    "    \n",
    "def euclid_dist(t1, t2):\n",
    "    return np.sqrt(((t1-t2)**2).sum(axis = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replaces occurrences of a substring from the right side of the original string with a new substring, up to a specified count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replaceRight(original, old, new, count_right):\n",
    "    repeat=0\n",
    "    text = original\n",
    "    old_len = len(old)\n",
    "    \n",
    "    count_find = original.count(old)\n",
    "    if count_right > count_find: \n",
    "        repeat = count_find\n",
    "    else :\n",
    "        repeat = count_right\n",
    "\n",
    "    while(repeat):\n",
    "      find_index = text.rfind(old)\n",
    "      text = text[:find_index] + new + text[find_index+old_len:]\n",
    "\n",
    "      repeat -= 1\n",
    "      \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File paths for training and validation labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label_path = '/data/labels/train/'\n",
    "# val_label_path = '/data/labels/validation/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the markings of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marking_train = get_axial_marking(train_label_path)\n",
    "# marking_val = get_axial_marking(val_label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the dataset that will be used for the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset_aug = DatasetRetriever_cmbs(\n",
    "#     image_ids=np.array(marking_train['image_id']),  #array with image_ids\n",
    "#     marking=marking_train, \n",
    "#     transforms=get_train_transforms(),\n",
    "#     test=False,\n",
    "# )\n",
    "\n",
    "# validation_dataset = DatasetRetriever_cmbs(\n",
    "#     image_ids=np.array(marking_val['image_id']),\n",
    "#     marking=marking_val,\n",
    "#     transforms=get_valid_transforms(),\n",
    "#     test=True,\n",
    "# )\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_ids, all_labels, test_size=0.33, random_state=42)\n",
    "\n",
    "train_dataset_aug = VALDODataset(\n",
    "    img_paths=X_train, ann_paths=y_train, transform=transform\n",
    ")\n",
    "\n",
    "validation_dataset = VALDODataset(\n",
    "    img_paths=X_test, ann_paths=y_test, transform=transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fitter:\n",
    "\n",
    "    def __init__(self, model, device, config):\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.base_dir = f'./{config.folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "\n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "        self.best_summary_loss = 10 ** 5\n",
    "\n",
    "        self.model = model\n",
    "        self.device = device\n",
    "\n",
    "        param_optimizer = list(self.model.named_parameters())\n",
    "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
    "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss = self.train_one_epoch(train_loader)\n",
    "\n",
    "            self.log(\n",
    "                f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            self.save(f'{self.base_dir}/last-checkpoint.bin')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss = self.validation(validation_loader)\n",
    "\n",
    "            self.log(\n",
    "                f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            if summary_loss.avg < self.best_summary_loss:\n",
    "                self.best_summary_loss = summary_loss.avg\n",
    "                self.model.eval()\n",
    "                self.save(f'{self.base_dir}/best-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-checkpoint-*epoch.bin'))[:-3]:\n",
    "                    os.remove(path)\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step(metrics=summary_loss.avg)\n",
    "\n",
    "            self.epoch += 1\n",
    "\n",
    "    def validation(self, val_loader):\n",
    "        self.model.eval()\n",
    "        summary_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, targets, image_ids) in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                images = torch.stack(tuple(images))\n",
    "                batch_size = images.shape[0]\n",
    "                images = images.to(self.device).float()\n",
    "                boxes = [target['boxes'].to(self.device).float() for target in targets]\n",
    "                labels = [target['labels'].to(self.device).float() for target in targets]\n",
    "\n",
    "                model_targets = {\n",
    "                \"boxes\": boxes,\n",
    "                \"labels\": labels\n",
    "                }\n",
    "\n",
    "                loss, _, _ = self.model(images, model_targets)\n",
    "                summary_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "        return summary_loss\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        for step, (images, targets, image_ids) in enumerate(train_loader):\n",
    "            print(\"Images:\", images)\n",
    "            print(\"Targets:\", targets)\n",
    "            print(\"Ids:\", image_ids)\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            images = torch.stack(tuple(images))\n",
    "            images = images.to(self.device).float()\n",
    "            batch_size = images.shape[0]\n",
    "            boxes = [target['boxes'].to(self.device).float() for target in targets]\n",
    "            labels = [target['labels'].to(self.device).float() for target in targets]\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            model_targets = {\n",
    "                \"boxes\": boxes,\n",
    "                \"labels\": labels\n",
    "            }\n",
    "\n",
    "            loss, _, _ = self.model(images, model_targets)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            summary_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "        return summary_loss\n",
    "\n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'best_summary_loss': self.best_summary_loss,\n",
    "            'epoch': self.epoch,\n",
    "        }, path)\n",
    "\n",
    "    def load(self, path):\n",
    "        checkpoint = torch.load(path)\n",
    "        self.model.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "        self.best_summary_loss = checkpoint['best_summary_loss']\n",
    "        self.epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainGlobalConfig:\n",
    "    num_workers = 0\n",
    "    batch_size = 1\n",
    "    n_epochs = 10\n",
    "    lr = 0.0001\n",
    "\n",
    "    folder = 'Model_Save(Axial)_D7'\n",
    "\n",
    "    # -------------------\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    # -------------------\n",
    "\n",
    "    # --------------------\n",
    "    step_scheduler = False # do scheduler.step after optimizer.step\n",
    "    epoch_scheduler = False\n",
    "    validation_scheduler = True # do scheduler.step after validation stage loss -> For scheduler 'ReduceLROnPlateau'\n",
    "    \n",
    "#     SchedulerClass = torch.optim.lr_scheduler.OneCycleLR\n",
    "#     scheduler_params = dict(\n",
    "#         max_lr=0.001,\n",
    "#         epochs=n_epochs,\n",
    "#         steps_per_epoch=2*int(len(train_dataset_aug) / batch_size),\n",
    "#         pct_start=0.31,\n",
    "#         anneal_strategy='cos', \n",
    "#         final_div_factor=10**4\n",
    "#     )\n",
    "\n",
    "#     SchedulerClass = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts\n",
    "#     scheduler_params = dict(\n",
    "#         T_0=5,        # Number of iterations for the first restart.\n",
    "#         T_mult=2,    \n",
    "#         eta_min=0.00004,\n",
    "#         last_epoch=-1, \n",
    "#         verbose=False\n",
    "#     )\n",
    "\n",
    "#     SchedulerClass = torch.optim.lr_scheduler.ExponentialLR\n",
    "#     scheduler_params = dict(\n",
    "#         gamma = 0.7\n",
    "#     )\n",
    "\n",
    "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
    "    scheduler_params = dict(\n",
    "        mode='min',\n",
    "        factor=0.1,\n",
    "        patience=1,\n",
    "        verbose=False, \n",
    "        threshold=0.0001,\n",
    "        threshold_mode='abs',\n",
    "        cooldown=0, \n",
    "        min_lr=0,\n",
    "        eps=1e-08\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training process of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "\n",
    "    net = get_net()\n",
    "    device = torch.device('cuda:0')\n",
    "    print('============================================================================================================================================================================')\n",
    "    print(device)\n",
    "    net.to(device)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset_aug,\n",
    "        batch_size=TrainGlobalConfig.batch_size,     \n",
    "        sampler=RandomSampler(train_dataset_aug),\n",
    "        pin_memory=False,\n",
    "        drop_last=False,   #drop last one for having same batch size\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        validation_dataset, \n",
    "        batch_size=TrainGlobalConfig.batch_size,\n",
    "        num_workers=TrainGlobalConfig.num_workers,\n",
    "        shuffle=False,\n",
    "        sampler=SequentialSampler(validation_dataset),\n",
    "        pin_memory=False,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
    "    best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val = fitter.fit(train_loader, val_loader)\n",
    "    \n",
    "    return best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This will return the efficientdet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To get the weights:\n",
    "\n",
    "1. Go to: https://github.com/rwightman/efficientdet-pytorch/releases\n",
    "2. Look for Weights in the bottom\n",
    "3. Find \"efficientdet_d7-f05bf714.pth\"\n",
    "4. Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = get_efficientdet_config('tf_efficientdet_d7')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.image_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.image_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================================================================================================\n",
      "cuda:0\n",
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2024-05-15T15:05:53.817313\n",
      "LR: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Temp\\ipykernel_29192\\1402228704.py:32: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().isoformat()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images: tensor([[[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]],\n",
      "\n",
      "\n",
      "        [[[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]],\n",
      "\n",
      "         [[0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          ...,\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0],\n",
      "          [0, 0, 0,  ..., 0, 0, 0]]]], dtype=torch.uint8)\n",
      "Targets: [{'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([[340., 227., 360., 247.]]), 'labels': tensor([1])}, {'boxes': tensor([[339., 226., 359., 246.]]), 'labels': tensor([1])}, {'boxes': tensor([[339., 226., 359., 246.]]), 'labels': tensor([1])}, {'boxes': tensor([[339., 227., 359., 247.]]), 'labels': tensor([1])}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}, {'boxes': tensor([]), 'labels': tensor([], dtype=torch.int64)}]\n",
      "Ids: ['c:\\\\Users\\\\Lex Zedrick Lorenzo\\\\Documents\\\\GitHub\\\\VALDO_Dataset\\\\Task2\\\\sub-232\\\\sub-232_space-T2S_desc-masked_T2S.nii.gz']\n",
      "Train Step 0/48, summary_loss: 0.00000, time: 3.01087\r"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 2.63 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[753], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m     net\u001b[38;5;241m.\u001b[39mclass_net \u001b[38;5;241m=\u001b[39m HeadNet(mutable_config, num_outputs\u001b[38;5;241m=\u001b[39mmutable_config\u001b[38;5;241m.\u001b[39mnum_classes) \u001b[38;5;66;03m#Use default batchnorm\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DetBenchTrain(net, mutable_config)\n\u001b[1;32m---> 18\u001b[0m best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val \u001b[38;5;241m=\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[748], line 29\u001b[0m, in \u001b[0;36mrun_training\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m     19\u001b[0m     validation_dataset, \n\u001b[0;32m     20\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mTrainGlobalConfig\u001b[38;5;241m.\u001b[39mbatch_size,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn,\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m fitter \u001b[38;5;241m=\u001b[39m Fitter(model\u001b[38;5;241m=\u001b[39mnet, device\u001b[38;5;241m=\u001b[39mdevice, config\u001b[38;5;241m=\u001b[39mTrainGlobalConfig)\n\u001b[1;32m---> 29\u001b[0m best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val \u001b[38;5;241m=\u001b[39m \u001b[43mfitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val\n",
      "Cell \u001b[1;32mIn[745], line 36\u001b[0m, in \u001b[0;36mFitter.fit\u001b[1;34m(self, train_loader, validation_loader)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtimestamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLR: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m t \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 36\u001b[0m summary_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[RESULT]: Train. Epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, summary_loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msummary_loss\u001b[38;5;241m.\u001b[39mavg\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mt)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/last-checkpoint.bin\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[745], line 115\u001b[0m, in \u001b[0;36mFitter.train_one_epoch\u001b[1;34m(self, train_loader)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    110\u001b[0m model_targets \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboxes\u001b[39m\u001b[38;5;124m\"\u001b[39m: boxes,\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m: labels\n\u001b[0;32m    113\u001b[0m }\n\u001b[1;32m--> 115\u001b[0m loss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_targets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    119\u001b[0m summary_loss\u001b[38;5;241m.\u001b[39mupdate(loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem(), batch_size)\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\effdet\\bench.py:157\u001b[0m, in \u001b[0;36mDetBenchTrain.forward\u001b[1;34m(self, x, target)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, target: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]):\n\u001b[1;32m--> 157\u001b[0m     class_out, box_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchor_labeler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# target should contain pre-computed anchor labels if labeler not present in bench\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_num_positives\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m target\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\effdet\\efficientdet.py:730\u001b[0m, in \u001b[0;36mEfficientDet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 730\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    731\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfpn(x)\n\u001b[0;32m    732\u001b[0m     x_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_net(x)\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\timm\\models\\efficientnet.py:250\u001b[0m, in \u001b[0;36mEfficientNetFeatures.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 250\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_stem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_hooks \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\timm\\layers\\conv2d_same.py:51\u001b[0m, in \u001b[0;36mConv2dSame.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconv2d_same\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\timm\\layers\\conv2d_same.py:27\u001b[0m, in \u001b[0;36mconv2d_same\u001b[1;34m(x, weight, bias, stride, padding, dilation, groups)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconv2d_same\u001b[39m(\n\u001b[0;32m     18\u001b[0m         x,\n\u001b[0;32m     19\u001b[0m         weight: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     24\u001b[0m         groups: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     25\u001b[0m ):\n\u001b[0;32m     26\u001b[0m     x \u001b[38;5;241m=\u001b[39m pad_same(x, weight\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:], stride, dilation)\n\u001b[1;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 2.63 GiB. GPU "
     ]
    }
   ],
   "source": [
    "def get_net():\n",
    "    config = get_efficientdet_config('tf_efficientdet_d7')\n",
    "\n",
    "    \n",
    "\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    checkpoint = torch.load('efficientdet_d7-f05bf714.pth')\n",
    "    net.load_state_dict(checkpoint)\n",
    "\n",
    "    mutable_config = OmegaConf.create(OmegaConf.to_container(config, resolve=True))\n",
    "    mutable_config.num_classes = 1\n",
    "    mutable_config.image_size = [512, 512]\n",
    "\n",
    "    net.class_net = HeadNet(mutable_config, num_outputs=mutable_config.num_classes) #Use default batchnorm\n",
    "    \n",
    "    return DetBenchTrain(net, mutable_config)\n",
    "\n",
    "best_val_loss, summary_loss_over_itr_train, summary_loss_over_itr_val = run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_path = 'data/labels/test/'\n",
    "IMAGE_ROOT_PATH_AXIAL = 'data/images/axial/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth annotations for CMB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Temp\\ipykernel_16828\\2908703177.py:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  numbers_axial = re.findall(\"\\d+\", image_id)\n",
      "C:\\Users\\Lex Zedrick Lorenzo\\AppData\\Local\\Temp\\ipykernel_16828\\2908703177.py:5: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  numbers_axial = re.findall(\"\\d+\", image_id)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'marking_test_all_axial' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m         marking_cd_gt_axial \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([marking_cd_gt_axial, temp], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m marking_cd_gt_axial\n\u001b[1;32m---> 18\u001b[0m num_cmbs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[43mmarking_test_all_axial\u001b[49m[marking_test_all_axial[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'marking_test_all_axial' is not defined"
     ]
    }
   ],
   "source": [
    "def make_marking_cd_gt_axial(marking_test_axial):\n",
    "    marking_cd_gt_axial = pd.DataFrame(columns=['patient_id', 's', 'x', 'y'])\n",
    "    for i in range(len(marking_test_axial)):\n",
    "        image_id = marking_test_axial.loc[i]['image_id']\n",
    "        numbers_axial = re.findall(\"\\d+\", image_id)\n",
    "        slice_num_axial = int(numbers_axial[-1])\n",
    "        patient_id = replaceRight(image_id, '_'+str(slice_num_axial), '', 1)\n",
    "\n",
    "        x = 512*marking_test_axial.loc[i]['x']/360\n",
    "        y = 512*marking_test_axial.loc[i]['y']/360    \n",
    "\n",
    "        temp = pd.DataFrame(columns=['patient_id', 's', 'x', 'y'])\n",
    "        temp.loc[0] = [patient_id, slice_num_axial, x, y]\n",
    "        marking_cd_gt_axial = pd.concat([marking_cd_gt_axial, temp], ignore_index=True)\n",
    "\n",
    "    return marking_cd_gt_axial\n",
    "\n",
    "num_cmbs=len(marking_test_all_axial[marking_test_all_axial['y']!=1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions in Axial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_axial(images, score_threshold=0.29): #Confidence score...? Default 0.22\n",
    "    device = torch.device(device_num)\n",
    "    images = torch.stack(images).to(device).float()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        det = net_axial(images, torch.tensor([1]*images.shape[0]).float().to(device))\n",
    "        for i in range(images.shape[0]):\n",
    "            boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "            scores = det[i].detach().cpu().numpy()[:,4]\n",
    "            indexes = np.where(scores > score_threshold)[0]\n",
    "            boxes = boxes[indexes]\n",
    "            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "            predictions.append({\n",
    "                'boxes': boxes[indexes],\n",
    "                'scores': scores[indexes],\n",
    "            })\n",
    "    return [predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Boxes Fusion (WBF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wbf_axial(predictions, image_index, image_size=512, iou_thr=0.45, skip_box_thr=0, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting False Positives and True Positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fptp(marking_cd_gt_patient, marking_cd_gt, marking_cd_slice, slice_num, patient_name, x, y):\n",
    "    #tp_candi -> near_gt: x,y cordi of ground truth from slices adjacent to predicting slice\n",
    "    #fp_candi -> near_pd: x,y cordi of predicted boxed from slices adjacent to predicting slice\n",
    "    #near_gt: ground truths (x, y cordi info) in near slices (upper and lower) from current images  \n",
    "    #near_pd: detections (slice, x, y cordi info) in near slices (only upper) from current images\n",
    "    global fp \n",
    "    global fp_count\n",
    "    global tp \n",
    "    global tp_count\n",
    "    \n",
    "    near_gt = marking_cd_gt_patient.loc[abs(slice_num-marking_cd_gt['s'])<5][['x','y']].to_numpy(dtype=float) #GT adjacent to prediction\n",
    "    near_pd = marking_cd_slice.loc[(slice_num-marking_cd_slice['s']<5)&(marking_cd_slice['patient_id']==patient_name)][['x','y']].to_numpy(dtype=float)\n",
    "\n",
    "    #count fp \n",
    "    if near_gt.shape[0]!=0:  #if predicted slice is adjacent to GT slices\n",
    "        dists_from_gt_list = euclid_dist([x, y], near_gt)\n",
    "        if dists_from_gt_list.min() > 20: #if the prediction is far from gt->FP in x, y cordi\n",
    "            #check whether the fp is consecutive or not\n",
    "            if near_pd.shape[0]!= 0: #\n",
    "                if euclid_dist([x, y], near_pd).min() > 10: #not consecutive detection.\n",
    "                    fp_count +=1\n",
    "                    fp = np.append(fp, np.array([[patient_name, slice_num, x, y, 0]]), axis=0)\n",
    "            else:\n",
    "                fp_count +=1\n",
    "                fp = np.append(fp, np.array([[patient_name, slice_num, x, y, 1]]), axis=0)\n",
    "        \n",
    "        else: #if the prediction is close to gt -> TP\n",
    "            for q in range(len(near_gt)):\n",
    "                near_gt_index = marking_cd_gt_patient.loc[(marking_cd_gt['x']==near_gt[q][0]) & (marking_cd_gt['y']==near_gt[q][1])].index[0]\n",
    "                if dists_from_gt_list[q] < 30 and marking_cd_gt_patient.loc[near_gt_index, 'state'] != 1: # if the gt is close to prediction and not detected.\n",
    "                    #check whether the tp is consecutive or not\n",
    "                    if near_pd.shape[0] != 0: #There are dets in the near slices \n",
    "                        if euclid_dist([x, y], near_pd).min() > 5: #there is no close x, y det -> not consecutive. 5\n",
    "                            tp_count += 1\n",
    "                            tp = np.append(tp, np.array([[patient_name, slice_num, x, y, 0]]), axis=0)\n",
    "                            marking_cd_gt_patient.loc[near_gt_index, 'state'] = 1\n",
    "                    else:\n",
    "                        tp_count += 1\n",
    "                        tp = np.append(tp, np.array([[patient_name, slice_num, x, y, 1]]), axis=0)\n",
    "                        marking_cd_gt_patient.loc[near_gt_index, 'state'] = 1\n",
    "                        \n",
    "    else:   #Predicted slice is not adjacent to that of GTs               \n",
    "        if i == 0:   #first slice\n",
    "            fp_count +=1\n",
    "            fp = np.append(fp, np.array([[patient_name, slice_num, x, y, 2]]), axis=0)\n",
    "        else:  \n",
    "            if near_pd.shape[0] != 0:\n",
    "                if euclid_dist([x, y], near_pd).min() > 10:\n",
    "                    fp_count +=1\n",
    "                    fp = np.append(fp, np.array([[patient_name, slice_num, x, y, 3]]), axis=0)\n",
    "            else:\n",
    "                fp_count +=1\n",
    "                fp = np.append(fp, np.array([[patient_name, slice_num, x, y, 4]]), axis=0)\n",
    "    return fp, fp_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not Sure pero sabi ni ChatGPT pang evaluate daw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_net(checkpoint_path):\n",
    "    config = get_efficientdet_config('tf_efficientdet_d3')\n",
    "    net = EfficientDet(config, pretrained_backbone=False)\n",
    "    \n",
    "    config.num_classes = 1\n",
    "    config.image_size=512\n",
    "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01)) # Configures the classification head of the model\n",
    "\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device_num)\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    del checkpoint\n",
    "    gc.collect()\n",
    "\n",
    "    net = DetBenchEval(net, config)\n",
    "    net.eval();\n",
    "    device = torch.device(device_num)\n",
    "    return net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_axial = load_net('../Model/best-checkpoint.bin')\n",
    "net_sagittal = load_net('../Model/best-checkpoint.bin')\n",
    "net_coronal = load_net('../Model/best-checkpoint.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_all_axial = DatasetRetriever_cmbs(\n",
    "    image_ids=np.array(marking_test_all_axial['image_id']),\n",
    "    marking=marking_test_all_axial,\n",
    "    transforms=get_valid_transforms_axial(),\n",
    "    test=False,\n",
    "    image_root_path = IMAGE_ROOT_PATH_AXIAL,\n",
    ")\n",
    "\n",
    "test_data_loader_all_axial = DataLoader(\n",
    "    test_dataset_all_axial,\n",
    "    batch_size=32,     #batchsize = 4\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    "    collate_fn=collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions_axial(images, score_threshold=0.29): #Confidence score...? Default 0.22\n",
    "    device = torch.device(device_num)\n",
    "    images = torch.stack(images).to(device).float()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        det = net_axial(images, torch.tensor([1]*images.shape[0]).float().to(device))\n",
    "        for i in range(images.shape[0]):\n",
    "            boxes = det[i].detach().cpu().numpy()[:,:4]    \n",
    "            scores = det[i].detach().cpu().numpy()[:,4]\n",
    "            indexes = np.where(scores > score_threshold)[0]\n",
    "            boxes = boxes[indexes]\n",
    "            boxes[:, 2] = boxes[:, 2] + boxes[:, 0]\n",
    "            boxes[:, 3] = boxes[:, 3] + boxes[:, 1]\n",
    "            predictions.append({\n",
    "                'boxes': boxes[indexes],\n",
    "                'scores': scores[indexes],\n",
    "            })\n",
    "    return [predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_wbf_axial(predictions, image_index, image_size=512, iou_thr=0.45, skip_box_thr=0, weights=None):\n",
    "    boxes = [(prediction[image_index]['boxes']/(image_size-1)).tolist()  for prediction in predictions]\n",
    "    scores = [prediction[image_index]['scores'].tolist()  for prediction in predictions]\n",
    "    labels = [np.ones(prediction[image_index]['scores'].shape[0]).tolist() for prediction in predictions]\n",
    "    boxes, scores, labels = weighted_boxes_fusion(boxes, scores, labels, weights=None, iou_thr=iou_thr, skip_box_thr=skip_box_thr)\n",
    "    boxes = boxes*(image_size-1)\n",
    "    return boxes, scores, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
